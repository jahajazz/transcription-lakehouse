{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":0.24,"end":8.96,"speaker":"Dr. Paula Boddington","text":"I think ChatGPT stops at collecting data at 2021, I think. But if it carries on updating the data, it's going to be collecting its own data. It's going to be like."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":9.12,"end":105.25,"speaker":"Jonathan Pageau","text":"It's going to be a feedback loop. That's really the biggest thing that I'm seeing, is that if you project AI very long term, it's going to be diminishing. It'll be diminishing returns and a kind of, you know, when people talk about, like, singularity and like AI, you know, exploding and becoming, I don't see how that's possible, because it has no relevance, it has desires. And so all it can ultimately be is a kind of spinning back onto itself with. Maybe with a long arc, but on that long arc, you're looking at a kind of. Of leveling, you know, a kind of intelligence leveling. I don't see. I can't see otherwise. This is Jonathan Peugeot. Welcome to the Symbolic. So, hello, everyone. I'm here with Paula Boddington. Those of you who've watched my channel have seen us talk on several subjects. She is an ethicist. She also teaches in different. Different institutions. And she's been thinking a lot about, you know, the relationship between biology and ethics, but also technology and ethics. And so it seems like, you know, this is the perfect time to talk about it. With arising of AI and also the kind of madness around self identification, all of this is kind of happening all at the same time. And so, Paula, thanks for talking to me again."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":105.65,"end":112.69,"speaker":"Dr. Paula Boddington","text":"Oh, really great to talk to you. A main problem is trying to focus on something where it doesn't just go all over the place because everything is so interconnected."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":112.85,"end":150.23,"speaker":"Jonathan Pageau","text":"Yeah, well, I'd like to know a little bit about. Because AI is now really exploded. And we've also. Not only has it exploded, but the religious aspect of AI seems to be coming more and more to the foreign, you know, with Elon Musk going on the record talking about the heads of Google literally saying they're building a God, you know, and. And then many of the transhumanists, you know, have pronounced themselves in publications. But now it's becoming more and more obvious that there is a religious aspect to AI even in the people that are making it. And so I don't know if you had thoughts about where we are now with ChatGPT taking over, really, within just to a few months. All of a sudden, it's everywhere."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":150.7,"end":258.41,"speaker":"Dr. Paula Boddington","text":"Okay. Yeah, well, I mean, I have lots of. I have. There's lots of things that could be said about this. So, I mean, so the religious aspect of AI has been there really for a long time. And maybe it might be also helpful to start off by clarifying some things, because there are a lot of people who work, who are basically working in that field who no longer will use the term AI because it's so confusing. So they might be doing. So there are people who are trying to, say, build artificial general intelligence or trying to build AI with very, very broad capacities, and other people who are working on really discreet issues, like, for example, using a. Using AI to improve reading of medical images, accuracy of how you diagnose cancers, and so on. A lot of those people, there's big divisions ideologically within people working on this. A lot of those people will now just prefer to talk about machine learning rather than AI, because I think it could be helpful. It's important to break up different ways of looking at it so we can think about AI in terms of the ideology of what we're actually calling artificial intelligence. We can also think about the actual mechanisms of software involved. We can think about the hardware and how it's infiltrating our lives and the infrastructure so they can all operate on different kinds of levels. So even one question, even, is whether or not how it got called artificial intelligence, which is, in a sense, a sort of. Historically, it dates from summer school in 1956 at Dartmouth where John McCarthy and, like, a score of people got together because they thought they'd be able to build, like, an intelligent machine over a summer. So hilarious, really. And so that's how the name stuck. But a lot of people don't really like the name because intelligence has got so such broad connotations. A lot of things is really, really discreet. But for ChatGPT is really interesting. So thinking about what avenue to go."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":258.41,"end":293.31,"speaker":"Jonathan Pageau","text":"Down, one of the things that chatgpt, the reason why it's so interesting is because unlike, for example, using AI to diagnose cancer, what ChatGPT is doing is that it's a chatbot. It's interacting with humans, and it's interacting with the public, which means that it' not an elite question of, of asking ourselves, you know, what is this doing? Where are we pointing this? No, it's. It's. It's basically loosed onto the public, and it's acting really in all kinds of ways that are unpredictable. Maybe they are predictable. But it's becoming, you know, really. I think it's becoming something like a form of divination for people, and people are treating it that way."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":293.39,"end":569.82,"speaker":"Dr. Paula Boddington","text":"Yeah, yeah, it is it's, it is, it's kind of becoming a sort of better way of kind of reading your horoscope, isn't it, and trying to find answers, find answers to things. So, but I think it's really interesting to think about the question about the fact that ChatGPT is about language because not, I mean, not all AI is about language, but I think it's really easy to fall into thinking maybe this is conscious, it's really an agent, simply because of the fact that it's focused on linguistic intelligence, which is only one aspect of intelligence. So I think one of the things that's going on is that we're drawn towards some of the things going on with AI sort of emanate from AI and some are about general things in the culture, in the air, which feed around in a circle and then help to shape how we're thinking of AI. So focusing on intelligence is really, really closely connected to like Cartesian notions of the mind and the body, thinking that what we are essentially is just some mental substance and focusing very much on cognition as a hallmark of humans. And in particular, even a cognitive. All cognition is not language. In particular, thinking of linguistic skills and falling back, I actually, because I had so many different things we could talk about. Where did I write it down? I wrote down a sketch of a sort of feedback. There are feedback loops. So I was like, I was really interested in your video you did about a month ago about AI and Moloch and how it's a form of agency, which I think you're right about that. But I think it can be really interesting to break it down and see how it's operating, because in some ways it acts as a kind of ever escalating feedback loop. But there also are ways in which it's operating on us as agents and it's getting us to carry along with it like a, kind of like, you know, for example, like you can get funguses that infect ants, that make the ants behave weirdly and they go up and die and spread the fungus, that kind of thing. But also one of the things that's happening, I think is that it's breaking things down in a way that, that if we're thinking really carefully, it gives us the capacity to go back and see, hang on, this is wrong, this is not working. We can go back and see what the problem is. So if we take the general, like, let me just illustrate, it kind of operates a bit like, I think it operates. It can operate a bit like as using a metaphor of how Bushfires spread. So they can spread in Australia. But I used to live, I know they can spread really, really rapidly. One reason is because you get the eucalyptus gas forming balls of fire that leap ahead. But then after the fire, there's kind of devastation. But there are eucalyptus trees that will only sprout from seed if they've been through a fire. So that new things can come up. So there's a kind of like a cycle of things that are happening. So if we go back to the notion that some people are trying to build AI to be like a God, and there's theology in AI, one of the things that's happening is that there's a response to AI, but we need to try to combat it. So we need to think about the ethics of AI. So we need to have ways of trying to think about that. And one of the problems with that, one of the problems of ways of trying to think about that is that the standard ways we've been thinking about ethics kind of break down so that you can think about ethics in terms of, broadly, in terms of harms and benefits across a population. But we can't just carry on with old notions of harms and benefits because what we think of as a harm and what we think of as a benefit is changing because of technology. And so like a basis, I mean, like a really popular, commonly used way of looking at ethics, a utilitarian model would be based upon. We need to try to fulfill human desires and to try to work out what our desires really are. You know, not our kind of short term desires, but what our higher, higher end desires are. But what AI is doing is hacking our desires. It's working on us as an object and hacking them. So what that then means is that this ethical basis of simply looking at fulfilling our desires or what makes us happy cannot be used. We should understand it cannot be used. Which means we then have to go to try to think really clearly and what the basis of our values are, which can end up going back to thinking we need to think about God or certainly some higher value. Yeah, so you sort of mean by the. Have I explained that? Okay, like you can kind of get a loop where we do actually have to. So, yeah, so yeah, so yeah, so we have to think about. We end up having to think about not just some superficial notion of ethics, but about human nature, where we are in the universe because of the fact it's being taken apart by AI. So I'm a bit pessimistic and a bit optimistic, but I think we need to Think really carefully about it. Have I explained that? Okay."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":569.82,"end":584.14,"speaker":"Jonathan Pageau","text":"No, I think, I think you. I think you've explained it well. Yeah, let me, Let me, let me think about what you said. One of the issues that AI is doing, and it's something like it's what technology does in general."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":584.46,"end":584.86,"speaker":"Dr. Paula Boddington","text":"Yes."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":584.86,"end":631.64,"speaker":"Jonathan Pageau","text":"Is that it increases power and it externalizes the means. Right. It's like, so you have these means of action and those means get externalized, but the intention is usually always in the person. Right. So a car makes you more powerful, makes you go faster, but you need to add things to you. And what AI seems to be doing, and it's not just AI, it's in general information technology seems to have been doing that for a while, is that it's externalizing, thinking and externalizing the very process of thinking and what you need to get to the. So you can remain with a desire, let's say, or a question. But the means by which you get to the answer is now completely. Can be completely externalized."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":631.72,"end":632.72,"speaker":"Dr. Paula Boddington","text":"Yes, you need."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":632.72,"end":653.57,"speaker":"Jonathan Pageau","text":"No, you need to. And so at the very least, what AI seems to be able to do is to increase our power in a way that will also atrophy the muscle of intelligence that humans have. And so then that bigger question, like you asked, like, what it is to. What does it mean to be human?"}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":654.05,"end":654.41,"speaker":"Dr. Paula Boddington","text":"Yeah."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":654.41,"end":667.73,"speaker":"Jonathan Pageau","text":"And then also, what does it mean to be happy? Like, what is it that. Are we just people who want the kick? Like, we just want. Do we just want it to happen or do the very process of being involved in something is part of what gives us meaning and purpose."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":667.97,"end":723.94,"speaker":"Dr. Paula Boddington","text":"Yeah. Yeah, precisely. So, but people who are producing this aren't hoping, I think, this. When people talk about, oh, technological unemployment. And they'll be, you don't need to do any work anymore. They're going to be working, they're going to be building all this. They work because they enjoy it. I mean, they're workaholics and they think the rest of us are just going to sit around doing nothing. But it so depends on what it is that you want to do. There are some things where it's kind of like if you need to organize lots of numbers, it's really handy to be able to do it fast, to outsource that. But other things, we want to do it ourselves. I mean, what's the first thing kids start saying is that I want to tie my own shoelaces up, I want to do it. Stuff yourself. So that's, that's. It's taking us away. But it's Also, it is actually atropying us. So do. So that's what ChatGPT is doing. It doesn't do it on its own. So. So of course, for example, the first people, immediately people in education were really worried because immediately people started cheating on their essays right away."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":723.94,"end":732.71,"speaker":"Jonathan Pageau","text":"I mean, it's like my kids found out about it in five minutes and they knew exactly how to use it and it was like. And all their classmates know how to use it. So."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":732.86,"end":758.86,"speaker":"Dr. Paula Boddington","text":"So yeah, yeah. But if, but if you think about you, but you think, if you think about the incentives for doing that, why would you be incentivized to cheat on an exam? It's only because education, what's happened in education, the idea of education is about getting a formal certificate so you can prove that you can do it to get to the next step. Not about actually wanting to learn it for your own sake. If you really wanted to. If you really wanted to learn. I mean like when you learn carving, you didn't think, oh, I wish I could just get it done by a machine, did you?"}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":759.18,"end":761.64,"speaker":"Jonathan Pageau","text":"No. At least not myself. Yeah, yeah."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":761.64,"end":810.29,"speaker":"Dr. Paula Boddington","text":"Here's the value of doing it. But so what it's doing to our language, so it'll be reducing our capacity to understand language for sure. More than that, it's controlling our language. So through ChatGPT, but also language in general online, it's being censored because of sensitive control for so called misinformation. Misinformation actually usually based upon a totally bogus knowledge of model of what science is because, you know, all scientific knowledge is up for grabs. It's also atrophying our capacity to learn language. You know, you just have to use spell check or something. But also it's also imposing a kind of uniformity on us, uniformity on language. So I actually, so I should mention, actually I wrote a book recently, I wrote a book. Can I advertise my book?"}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":810.29,"end":810.97,"speaker":"Jonathan Pageau","text":"Sure, of course."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":811.21,"end":812.65,"speaker":"Dr. Paula Boddington","text":"Okay. It came up a couple of months ago."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":812.99,"end":815.11,"speaker":"Jonathan Pageau","text":"AI Ethics. All right, AI Ethics."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":815.11,"end":895.57,"speaker":"Dr. Paula Boddington","text":"Yeah, it came out a couple of months ago, which is. I wrote it as a. I wrote it as a. I should, I should give you the information. Springer. It came out with it's look, it's really long. It's like I wrote it as a textbook to try to sort of put lots of ideas together. But even why I mentioned it now is because the publishers decided that they were going to use an AI editor to edit it. I couldn't believe it. I couldn't believe it. I mean, I thought my neighbors were going to Call the police. Because I was like shouting into my computer so much, you just couldn't believe what it did to it. But one of the really interesting things is I could choose between whether I wanted to use British spelling or American spelling. I used British spelling, which meant I used British English. And it really made me realize there are massive differences between American English and British English. And this AI couldn't tell the difference. It just put everything into American English, which, no offense to American English, but it's really different. And it kept changing. It kept changing the meaning. It just really kept changing my grammar. But the present tense is used slightly differently. I didn't even realize that. It really mucked it all up. But ChatGPT, I asked ChatGPT if it knows the difference between different forms of English because Indian English, again, is different. And then the regional dialects in Britain. No, it doesn't. It had no idea. So maybe it does now because I asked it, but so what that means it's doing. It's looking at all the stuff in English and just collating it into an amorphous mass of English."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":895.73,"end":896.17,"speaker":"Jonathan Pageau","text":"Yeah."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":896.17,"end":910.69,"speaker":"Dr. Paula Boddington","text":"So different ways of using English are all being collated into one. And then there's stuff online. I think ChatGPT stops at collecting data at 2021, I think, but if it carries on updating the data, it's going to be collecting its own data. It's going to be like."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":910.85,"end":948.24,"speaker":"Jonathan Pageau","text":"It's going to be a feedback loop. That's really the biggest thing that I'm seeing is that if you project AI very long term, it's. It's going to be diminishing. It'll be diminishing returns and a kind of, you know, when people. When people talk about, like, singularity and like, AI, you know, exploding and becoming. I don't see. I don't see how that's possible because it has no relevance, it has no desires. And so all it can ultimately be is a kind of spinning back onto itself with. Maybe with a long arc, but on that long arc, you're looking at a kind of leveling, you know, a kind of intelligence leveling. I don't see. I can't see otherwise."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":948.64,"end":995.23,"speaker":"Dr. Paula Boddington","text":"Yes, yes. Yeah, I know. So it's going to. It's going to be the same. So, like in music, apparently, how the music is set up online, I don't know much about technical details. It's set to a particular sort of calibration based on keyboards. And so it's just. It's a limited way of looking at the music. So if it's it all ends up online. It's the same with everything. Language is just going to. I asked ChatGPT about it, isn't it a problem? And it just replied. It's actually quite funny. I was asking ChatGPT about AI ethics. It's quite funny. What. It's kind of like a way of skimming the surface of how bad things are. It just replied by saying, but over. Human language has always evolved, but this is going to stop it evolving, isn't it? And it's always evolved in different ways. It's always evolved in. In really different ways. I mean, because. Yeah, it's different because it can't."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":995.23,"end":1018.33,"speaker":"Jonathan Pageau","text":"Because it's not referring to anything. That's the problem. It does. It has no relevance. And that's. And I think. But then I don't know if you listen to the discussion that if you saw John Vervecki's video on AI, I still need to talk to him about it explicitly. But he, he said the only solution to AI is embodiment. And not just embodiment, but biological embodiment. And then. So that it attains relevance."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1018.65,"end":1057.63,"speaker":"Dr. Paula Boddington","text":"Yeah, I completely agree, actually. I mean, I've listened to some of his stuff, but I just think that's one of the big problems. One of the big problems is how it's making us less and less embodied. So partly through. That's partly why I said we should think about how we're thinking of what AI is, the ideology of it. So that. Because so it's interesting how we think about intelligence. As soon as we start thinking about AI is intelligent based on its use of language, mostly we then start thinking if it's intelligent, therefore, maybe it's like us, maybe it's an agent, but intelligence is just one. One aspect of who we are and manifest in all sorts of embodied ways."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1057.89,"end":1106.07,"speaker":"Jonathan Pageau","text":"Yeah, but I think, I think our intuition. We did, we talked about this a long time ago where we talked about how the systems seem to be farming intelligence from humans and then basically acting as a extension of that farmed intelligence. That seems to be more and more true because Most of the AIs now are what they call hybrid AIs, which means that they're trained by humans using different methods. Like mid Journey is a. Is training, you know, because people Mid Journey will select, will produce several images and then you will choose which one to have midjourney refine. And so as you're doing that, you're constantly telling it what's good and what's bad. And so it seems like that that notion of that notion that, that AI is basically not intelligent or agentic the way that we think about it, but that it's, it's farming it from humans."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1106.15,"end":1210.01,"speaker":"Dr. Paula Boddington","text":"Yes. Yeah. It's also doing in terms of a hardware because in order to do that it needs hardware and the hardware is most. The hardware is mostly made, made by people working in really awful conditions, sometimes under conditions of slavery or what's effectively slavery. Kids in the Congo digging up minerals with their bare hands and people in China working in really appalling conditions. So, so that's another way in which it's hacking humanity. So, but it's so, so interestingly actually one of, one of the ways in which is also hacking our agency is in, is in responses to it to try to control, try to control it sometimes through like controlling what language people can say online and so on, but also through, through legislation. So the European Union has got an AI act which is just about to go through that they've been working on for a couple, for two or three years to try to try to reduce the harms of AI. So it's focusing on, it's focusing on, it's focusing on. Because AI can cover lots of different things. So it starts with trying to define AI and then it's focusing on trying to legislate about AI if it's going to cause sort of serious or major harms. But for preamble, the preamble to the act written. Written by, written by the. Going to sound a bit Brexit. Y. Now, the unelected Ursula van der Leyden, who's in the European Union, says that it's important to have legislation to control AI, to build public trust in AI so that we can, so that we can advance innovation, so that we can increase the uptake of innovation. So it's focused on human rights, but it's focused on the human rights of people within the European Union. Because if you're going to increase innovation, you're going to increase the hardware, which is mostly outsourced to people in the rest of the world who are working in really terrible conditions."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1210.25,"end":1277.67,"speaker":"Jonathan Pageau","text":"Yeah, yeah. But also, I mean, the idea that we, the reason is because you want to build public trust in AI. That's the reason why we're doing. It's like we. AI is a given. It's going to take over. And so now we want to build public trust in AI. You know, Paula, my daughter, who's 15, she, she received an email from the government, from the, the Education Ministry of Education, and it was asking her to fill out a Quiz online. Like, you know, a questionnaire online and you know, it said that she could win $50 or whatever. And the questionnaire was from the government asking her about AI and what they were doing is asking her what they think about AI school counselors for psychological issues. Yeah, that's where we are. Think about it. Because. And, and in the questionnaire it was basically suggesting that, you know, this, this AI counselor would not have any prejudices, wouldn't be racist, wouldn't be sexist. Right. And that. Yeah, it would, it would be able to avoid all the prejudices of a human counselor."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1278.22,"end":1282.46,"speaker":"Dr. Paula Boddington","text":"Well, for one thing, that's a complete lie because it's going to have prejudices built in by whoever built it."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1282.7,"end":1289.1,"speaker":"Jonathan Pageau","text":"Yeah, but there'll be the right people that built that, that put those, you know, there'll be the non hate prejudices. Right."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1289.42,"end":1384.08,"speaker":"Dr. Paula Boddington","text":"But wow. But also, I mean, one of the things that will be happening then, it'll be collecting data. Collects data on people all the time. It's constantly, we're constantly. So that's another way in which it spreads. That's another way in which the ideology spreads because of the metrics of all the data that's been collected. So all the time we're having data collected about us and all the time data that you thought was just ambient, sort of like junk data, turns out to be data that can tell you something about yourself or could potentially do that. So that's another way, that's another way in which we're being sort of trained or seduced into thinking a sort of mentalistic conception of a human being. Because you're trying to think that we're just basically therefore made up of information or made up of data. Yeah, but AI, human counselor. But also you might ask the question. So all these things are nested in other things going on around them. You know, the issue about cheating on exams with ChatGPT is nested in a wider issue about competitiveness in education and exams. And there's also an easy solution to that, which is, I got a really novel idea for that. You could just sit in a room at a desk with a piece of paper and a pencil. If you want to test what people know, you could do that. It's been something really novel. I don't think it's ever been done before. So a lot of it could really easily be sorted out that kind of way. But you might. When I was at school, there was no such thing as a school counsellor. Now maybe there should have been. Maybe there were some things, but were Overlooked. It was a bit more brutal in those days. But you might start thinking, why are so many school children, so many teenagers having such a massive range of mental health problems?"}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1384.08,"end":1392.6,"speaker":"Jonathan Pageau","text":"Yeah, yeah, there's, there's definitely some. There's definitely some. All of this is kind of crunching at the same time, which is this mental health crisis with, with young people."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1393,"end":1393.48,"speaker":"Dr. Paula Boddington","text":"Yeah."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1394.36,"end":1408.02,"speaker":"Jonathan Pageau","text":"But it does have to do with AI in the sense, you know, that it is the question of what it is to be human, what it is to be part of a society, what it means to be someone in a community. All these things are exploded right now."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1408.33,"end":1443.03,"speaker":"Dr. Paula Boddington","text":"Yes. Yeah. I mean, I think the pandemic really worsened it as well, actually, because lots of technology was introduced but just never went away. I mean, lots, lots and lots of things have just been introduced and they thought, oh, this works fine or it's slightly better in some way, and so they're just keeping it. But I think all the online presence again is just encouraging us to a disembodied way of relating to people. I think we've talked about this before, but it's, but you can get easy access to a sort of so called community, but it's just completely not the same as actually spending time with actual people, is it?"}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1443.03,"end":1501.6,"speaker":"Jonathan Pageau","text":"But it brings about this idea that some ways that we are these Cartesian disembodied things, there is a rift between your mind, your, Your identity and your body. You know, this is accelerated so much because the thing is that even this conversation, I mean, it's fine as a conversation, but I've noticed now, because now I've done both where I've talked to someone on Zoom, that I met them in person. And you know, there's all the, there are all these unconscious cues about a person that have nothing to do with just what you see and what you hear. But you know, body position, muscle tension, there's even smells, probably there's all these things that are part of our human engagement that, that we somehow, because of, because of these screens, we're able to alienate ourselves from. That seems to be part of what's feeding into the massive alienation between our bodies and our, our identities and our minds."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1501.68,"end":1541.63,"speaker":"Dr. Paula Boddington","text":"Yeah, yeah, I mean, I mean, it could be. So there's, there's so much, so much concern now about having people, for example, wanting their identity to be validated or being really upset if you don't completely agree what their identity is, as if it's really, really fragile. So I said, but I, but I think if, if you weren't Just online so much. If you were with somebody, you get, you get validation and a sense of belonging simply from, you know, sitting and having a cup of tea with somebody, even without speaking or just. I'm sure, I mean, I'm absolutely certain we pick up signals from people. We pick up. Because when we pick up signals from people, like we have electrical fields that go really a long way from our bodies. I'm sure that's one of the ways in which we, we, we are interconnected and have a sense of we're animals."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1541.63,"end":1574.4,"speaker":"Jonathan Pageau","text":"Like we are, we're human animals. We have bodies, animals, you know, they smell each other. They, they have like, as if we don't have any of those. We're just these, these. Exactly. We're just like these eyes and these, this mind. Yes, but, but that's, that is definitely, that's definitely part of the whole issue of what's going on. And the fact that we're able to conceive AI as being similar or even superior to us in terms of what, of intelligence and in terms of agency means that we, we are deeply misunderstanding what it is to be a person."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1574.8,"end":1666.17,"speaker":"Dr. Paula Boddington","text":"Yes, yes, yeah, yeah, precisely. So there's another aspect of work that I do that's. We're looking really closely into this. Did I, did I mentioned I'd work. I do some work part time with a group of sociologists. We look at the care of people with dementia in hospitals. So one of the things we're really, really, really concerned about is. So it's not to deny that dementia isn't a really difficult condition that can cause lots of cognitive issues, but it's to try to sort of fight back about the idea that we're simply cognitive creatures. And there's lots and lots of work that indicates that people have got. Can, even after they've lost almost all language, can retain a real strong sense of where they are in the community and of how to behave and a sense of belonging and understanding with other people and often mediated through things like. So a lot of the work we've done in. My colleagues have done in hospitals looks at things like even the clothing that people wear so that especially if you have dementia, if you're dressed in your own familiar clothing, it helps to give you a sense of where you are and who you are. But they're much less likely to have their own clothing on. We found much more likely just to be in a hospital gown for men, not to be shaved, lose their glasses and so on. So it's that sense of embodied belonging or just Left in beds, a person could be transformed if they're taken out of bed and just sit and have a cup of tea with somebody. That's not just. That happens for people with dementia. That happens for all of us."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1666.33,"end":1706.57,"speaker":"Jonathan Pageau","text":"Yeah. Well, the image of the old person sitting on their porch on their rocking chair, this is an image that we have here in Canada, for sure. You know, the idea that that person is there, but is also kind of not totally there, you know, but they're still there and they still have. They're still part of life and they still have their little routine and they do their things, and we kind of understand that maybe they're kind of slipping away into some extent, but that doesn't mean. Like you said that. Right, exactly. So now let's put them in a hospital bed, in a hospital gown, with a septicized walls, and let's just make it all worse because. Because now they're not part of anything."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1706.97,"end":1747.95,"speaker":"Dr. Paula Boddington","text":"Yes. Yeah. Yes. So we've got an artist, joined our team last term. Last year, she's doing some work with painting workshops with people who are living with dementia as a way of helping people to express ideas. Starting going along some of the workshops with her. So it's looking at the idea of the materiality of the paint as a way of actually. But this is actually a form of thinking that expressed through the materiality of what you can understand and communicate and express through the actual physical materials that you're using. So that's like a really embodied way of being a human and acting something out."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1748.19,"end":1792.01,"speaker":"Jonathan Pageau","text":"Yeah, but you can see it, like here in Canada especially, all of these things are definitely related because the scandal around Maid here, around Medical Assistant dying is. I mean, it's. Now it's blowing up, because I think it's just been a few years since it's become legal, and I think it's. 30,000 people have been. Have. Have gone through MAID. And so you can see that it is this idea that you. I mean, just this. This very idea that. Exactly. That you're this thing. And then at some point you decide, all right, now's my time to. To die. Because it's all cognitive. It's all. It's all mental. And so then you just decide, and then you die. And it's like. It really is this reduction of the human person to this abstract conscious being."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1792.33,"end":1814.73,"speaker":"Dr. Paula Boddington","text":"Yeah, Yeah. I mean, it's also related to the use of technology as well. Yeah, that's one of the things that's happening, is that you think that every problem must have a technological Solution or if you have a bit of technology, you must use it. Every desire must be fulfilled every time. If you're, if you have like this much pain that has to be taken away. Yeah."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1814.73,"end":1840.05,"speaker":"Jonathan Pageau","text":"And you can imagine that AI is going to be perfect for this because you know, you can take away the guilt or the, or the problem, ethical problem of the doctors having to make certain decisions where it's just the AI is going to decide who gets to live and who gets to die. And it'll be an objective decision. You know, it's all good. It's just like the AI counselor. You know, no prejudice. No, no. None of the human foibles. No guilt. No."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1840.55,"end":1870.51,"speaker":"Dr. Paula Boddington","text":"Yes, yes, but that probably will happen. But that is a way of also outsourcing responsibility because that would only happen within the context of a medical profession where, you know, people still, for some unknown reason tend to trust doctors. There's still an aura that this is somehow healthcare. How it gets labeled as health, as healthcare. If they did it in a butcher shop, that might be a better idea of what was actually happening."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1870.67,"end":1910.97,"speaker":"Jonathan Pageau","text":"Yeah, well, the doctors, at least here are almost already reduced to machines. If you go to the doctor now, all they do is sit in front of computer and fill out a report. As they're talking to you, they're sitting at their computer and they're filling out the report. And so they're already just basically data gathering. That's all they're doing. And their decision is kind of handed down by the system. And so, you know, it's just, it's just a question of time really before. Yeah, before this becomes more and more automated. Yeah, yeah. It's not, I mean, I'm definitely not a short term optimist on all these fronts."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1911.29,"end":1955.95,"speaker":"Dr. Paula Boddington","text":"Well, yeah, but yes, I mean there are so many. One of the things that's going on there is the use of metrics and also the idea that these IT systems are actually going to save time. We've been told that, we've been told that over and over and over and over again. Going to save time. Whereas I can, I can remember when I first started as a lecturer, you would just like write your reading list out on a piece of paper and give it to somebody to type. We have, we have so much more work to do. But the metrics, the metrics. And so one of the things the metrics doing is capture it and then the information belongs to this, belongs to the institution. So that's a way of controlling things. So I've noticed, you know, I've noticed that people are explicitly told that management can read your emails. So you just notice that everyone's being really polite about, oh, we got this change of university could be really good because, you know."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1955.95,"end":1958.43,"speaker":"Jonathan Pageau","text":"Because they're going to read your emails."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1959.55,"end":1959.87,"speaker":"Dr. Paula Boddington","text":"Yeah."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1959.87,"end":1964.19,"speaker":"Jonathan Pageau","text":"When you wrote something on a piece of paper and you gave it to someone, then nobody could read it, obviously."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1964.43,"end":1977.9,"speaker":"Dr. Paula Boddington","text":"Yeah, yeah. So. So that's how. It's how it's controlled. But it's also. It's always done in terms of this is going to say it's going to save you time. It's going to save time. So I would say they could introduce AI into medicine because then the doctors will have more time, like communicating with the patients."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1977.98,"end":1983.98,"speaker":"Jonathan Pageau","text":"Yeah, of course. Obviously that's what's going to happen. We all know that it's going to lead to doctors spending more time with patients."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1983.98,"end":1986.54,"speaker":"Dr. Paula Boddington","text":"My goodness, it's not going to happen."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1986.7,"end":1988.22,"speaker":"Jonathan Pageau","text":"There's no way that it's going to happen."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":1988.62,"end":2000.54,"speaker":"Dr. Paula Boddington","text":"But everything also is just reduced to metrics. That's one of the way which the AI is also, you know, is also controlling us by. If things are reduced to metrics, then what gets measured is what we look at."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2000.78,"end":2001.26,"speaker":"Jonathan Pageau","text":"Yeah."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2002.36,"end":2006.44,"speaker":"Dr. Paula Boddington","text":"If you reduce things to sort of harms and benefits, it depends on how you measure them."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2006.52,"end":2056.63,"speaker":"Jonathan Pageau","text":"So what do you think about in the Moloch video? What I was trying to present clearly, and it's not me who came up with this, obviously that's in the Moloch problem itself, is that we're so focused on the AI's agency and the fact whether or not AI becomes a consciousness or whatever, that we forget that we stop noticing the way that it's actually acting on us, which is sometimes outside of the software, outside of the hardware, but rather in the very competition to implement. So us as agents, we are in a competition to implement AI because we know that whoever implements it will have an advantage. And so it's almost like an evolutionary race towards implementation of AI. And so the agency seems to. That agency seems much stronger than the question of whether or not the software and the hardware or whatever become conscious."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2057.27,"end":2092.03,"speaker":"Dr. Paula Boddington","text":"Yeah, well, yes, there is a kind of arms race. There's lots of different sorts of arms races going on. So one of the problems that, like ordinary people have is working out what they can do about it. And I think there can be, on the one hand, you can say there's not much we can do about it, but I think there's a sort of a. There's a kind of a danger of thinking this is going to be some big crisis. So just let's wait for the crisis and something will happen. But I kind of think there's still way, there's still ways in which. There's still ways in which people can be aware of what's going on and try to get a bit more control in their life."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2092.11,"end":2145.89,"speaker":"Jonathan Pageau","text":"Because one of the things that AI is going to do, and this is something that I'm noticing already, you know, we're doing this, this Snow White project and we're going to see is going to be a deliberate focus on human intentionality will become what will happen. So it's not just that AI people think that AI is going to take over art, but I don't think so. I think that there'll be even a more of a fetishization of the art object with AI because it'll become very precious. You know, this idea of the actual someone making something will have a kind of aura that, you know, that all the like, let's say the wave, the drowning wave of mid journey images and of AI generated images won't have. So people will coagulate, will kind of rally around intention more. So that's a hopeful aspect of what AI seems to be bringing."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2146.43,"end":2218.35,"speaker":"Dr. Paula Boddington","text":"Yeah. Yes, I think, I think it will, I think it will lead to a turn to people actually wanting more human connection because they'll see it. I think. I'm sure that will happen. I mean, because why do people, I mean why do people actually go to galleries to see, you know, try, try to get to see the Mona Lisa. You can't get anywhere near it because people don't want to. People want to go and see the actual, the actual thing, don't they? I mean the galleries are just absolutely, absolutely crowded and so many, so many people will be, are. Are really keen to own a piece of art. Yeah, but something painted, even if it's not even. It's not like you might think it's not terribly good. They just love it because somebody has actually made it. I think there's going to be a move to people. I mean there is a move to people performing live music. I mean, because I mean live music like tin music is just nothing, nothing like. Just nothing like live performance. But also, even in terms of, even in terms of online censorship and people being, you know, permanently cancelled from things. There are people, people are, people are meeting up. So, you know, so people are, people are going. I know in London people are going to. They've been cancelled from so many different things, but their views on various things. People go and stand in speaker's Corner."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2218.43,"end":2218.79,"speaker":"Jonathan Pageau","text":"Yeah."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2218.79,"end":2221.23,"speaker":"Dr. Paula Boddington","text":"So you've got the police protecting you can say whatever you want."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2221.47,"end":2267.1,"speaker":"Jonathan Pageau","text":"Yeah. There's. When you talk about live music, and I think that that's a good example to help people understand the difference is that when you go to an event where there's people, there is a kind of electricity. I don't know what it is, but there is a kind of electricity that develops a kind of feeling of participating in a. In a group and a. Participating in a movement, participating in a wave that's going through that you cannot have. You just cannot have that when you're sitting at a screen. And so that, that, that will not go away. You know, the goggles, if you get the, the VR goggles, they're not going to provide that kind of, that kind of electricity that you get from going to a sports game or going to. Just can't."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2267.18,"end":2274.78,"speaker":"Dr. Paula Boddington","text":"No. No, they can't. I think I've heard you talk before about. With some. With a bit of skepticism about, like concerts and with comparison between taking."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2274.86,"end":2289.27,"speaker":"Jonathan Pageau","text":"Well, for sure. I think concerts are downstream from, From. From real participative actions. Like, you know, like whether it's folk dancing or religious participation, they're downstream from that, but they, they still have a level of reality that is undeniable."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2289.51,"end":2352.33,"speaker":"Dr. Paula Boddington","text":"Yeah. Yes, precisely. So if you, I mean, if you go, if you, if you go to see. I mean, actually, I've been. I've been to some fantastic operas recently. You get back up, you can't sleep for hours. You can't. Because it's just. But there are also. There are levels of participation in those sorts of things as well, because people who go to those. Or they'll know a lot about the performers. They'll, you know, join some society where they can go backstage. There's all sorts of levels of participation. But. But yet I think. I think that's the way. That's the way to go. Actually. Actually meeting up. Actually meeting up with. With people. There's some. Do you know, have I talked to you before? I mentioned there's a really interesting person who works in VR called. I hope I pronounced his name correctly, Jaron Lanier. L A N I E R. It's pronounced Lanier, I think. So he's one of the people who actually developed VR, but he's got some really interesting stuff to say. One of the things you might find he's got some videos online and a number of books, and one of the things he says about VR is the best thing about it is taking the headset off because then it makes you realize how absolutely fantastic reality is."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2353.05,"end":2384.25,"speaker":"Jonathan Pageau","text":"Yeah. Because the amount of colors, the amount of depth, like if you look, if you look at, you know, I was walking today, this morning, when you look at the sun like come through the leaves in a wooded area, you can have as much, you can have as much resolution on your 4k whatever. It's just not, you just can't compare it because you know, also you don't get like you say, you don't get the smell, you don't get feeling the heat coming, you know, from, from the sky. You don't have all these sensations that are so rich when you."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2385.3,"end":2405.54,"speaker":"Dr. Paula Boddington","text":"Yeah, that's something else I've noticed as well actually. So in order to counteract so much awful stuff online, I joined lots of, lots of, lots of kind of like Facebook groups like Welsh Landscape Photography, like the Corrugated Iron Appreciation Society, things like that. Just post photos of stuff and then people started posting, posting AI photos and things. People can tell, it's really quick."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2405.86,"end":2434.5,"speaker":"Jonathan Pageau","text":"You can tell right away. Yeah, I don't know. Like they keep telling us that at some point we won't be able to tell the difference between AI and. And real photos. But I'm not sure. At least you know, when they posted those pictures of the Pope, everybody got tricked by these pictures of the Pope. Like you could just tell that it was AI. I don't know. There's a, there's a subtle difference in the way that, that there's something about it. I mean maybe at some point we won't be able to tell, but at least for now it's quite still very easy to tell."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2435.06,"end":2444.75,"speaker":"Dr. Paula Boddington","text":"It's the same with GPT. A lot of people said oh this is really fantastic. It's. His answers are gave a really, really great. But you can, if you just keep on answering it, you can tell that it's, you can tell that it's just bullshit."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2445.55,"end":2457.07,"speaker":"Jonathan Pageau","text":"Well, it's, it's low level, whatever. It's just basically it can synthesize some, some things like in 10cent to be able to synthesize some, some, some ideas but they're very, it's very superficial."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2457.31,"end":2469.88,"speaker":"Dr. Paula Boddington","text":"Yes. I mean the other thing as well actually. Even if the end result is the same or already close enough to be good enough for what you want it. It hasn't, it hasn't got to the end result in anything like the same way."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2469.96,"end":2470.44,"speaker":"Jonathan Pageau","text":"Yeah."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2470.44,"end":2512.96,"speaker":"Dr. Paula Boddington","text":"In constructing it and constructing an image or doing a really good like AI painting or something. It hasn't been, it hasn't spent years in life drawing class. It doesn't it doesn't, it doesn't look at the figure and sort of, you know, if you go to drawing class and it'll, there'll be different techniques for sort of thinking about, you know, how you might think about what it is that you're seeing and how you might see. It doesn't do any of that. It doesn't do any of that at all. So, so in terms of saying it's intelligence, it can, it can do, it can do things and achieve a result, but whether it's, whether it's intelligence the same sort of way as us. So it's a really difficult question to fall in. So for ChatGPT, it just, it just predicts what the next word is likely to be. Like that?"}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2513.28,"end":2640.9,"speaker":"Jonathan Pageau","text":"No, but what's interesting about, about that is, you know, because the people who are programming AI and the people that are putting it together and amassing all this insane amount of language data and then pumping it into these, to these algorithms that are predicting the future, they don't understand, they don't think. They totally know what's encoded in human language. It is true that some of the very, very deep aspects of human consciousness will necessarily be encoded in the structures of languages. But the fact that that's true doesn't mean that those that are playing with this know what they're playing with, playing with these very dangerous tools. And some things are going to come out of AI that nobody will be able to predict because, because they're not aware of what the very, very strange and deep drive that exists within the human consciousness and also then ultimately are hidden in human language. So that's why it's, you know, when I talk about the idea that AI is, is like, you know, the body of a fallen angel, you know, people. I know that some people struggle to understand what I'm saying. They think I'm just talking about mythological images. And yeah, of course, the mythological image is captured very well, but in terms technically, you can understand it that way is to say that you don't know what's in human language. You don't know what all the motivators are. You don't know what all the hidden structures are that make that underlie meaning. And so we're just playing with this and we're kind of tossing the dice and, and tossing it around. But there are agencies in there that are very dark. The type of agencies that made human sacrifice other humans, the type of agencies that made people commit genocide. All these agencies are there in the very structure of human language. And the Fact that people don't seem to totally understand that. I mean, probably the raw version of ChatGPT has it all and now they're just trying to patch over it to stop that stuff from leaking out. But it's like it's probably there in the raw version of OpenAI. All that stuff is probably bubbling up all the time."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2641.3,"end":2666.95,"speaker":"Dr. Paula Boddington","text":"Yeah, well, yeah. I mean, there's so many attempts to try to work out ways of. General ways of trying to control AI. So I think I might have mentioned it to you before. Was it. Stuart Russell, for example, has written a book called Human Compatible, which is supposed to be a response to Nick Bostrom's book on superintelligence. So Nick Bostrom wrote this book a while ago now, actually, I think 2015 or 16, about. He's a paperclip. He's a paperclip guy."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2667.19,"end":2667.51,"speaker":"Jonathan Pageau","text":"Yeah."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2667.51,"end":2689.6,"speaker":"Dr. Paula Boddington","text":"About how much control super intelligence Stuart Russell is. He's like a real AI expert. Like, he knows what he's talking about. He wrote, he wrote the major textbook on AI Co, Reggie. He's got an idea that we should try to make certain that AI but we're producing is aligned with what humans want. But then the problem is what do humans want?"}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2689.84,"end":2691.44,"speaker":"Jonathan Pageau","text":"Right. Do you know what humans want?"}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2691.68,"end":2719.2,"speaker":"Dr. Paula Boddington","text":"He recognizes that problem. So here's his solution. Which is. Which is absolutely terrible. Honestly, he should just stick with AI and stop doing this. It's absolutely terrible because he thinks we should try to train AI to observe human behavior and extrapolate from our behavior. Honestly, he's got a book on his. He's got a book. He did. He did like a set of lectures on the BBC a year or two ago on it. Extrapolate from our behavior."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2719.52,"end":2719.92,"speaker":"Jonathan Pageau","text":"What."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2719.92,"end":2739.04,"speaker":"Dr. Paula Boddington","text":"What it is that we really want. What it is that we really want. So what's that going to be? What is that? I mean, but also, could you even interpret. You could probably interpret human behavior in, in any loads and loads of different ways. What, what do you. What do you. What do you really want? I mean, maybe. Maybe our darkest desires are really our stronger ones."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2739.12,"end":2758.12,"speaker":"Jonathan Pageau","text":"Right? Yeah, that's right. Exactly. Maybe the drive towards murder and war and rape and all these things, they're there. I don't know what to tell you. The idea that you would just watch, that you would just extrapolate from human language and human behavior. It's just not. That's just not gonna fly."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2758.44,"end":2764.12,"speaker":"Dr. Paula Boddington","text":"Yeah. You know, that was like, P.S. please exclude all Hannibal lectotypes and then also exclude."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2764.68,"end":2800.67,"speaker":"Jonathan Pageau","text":"Yeah, but there's, but there's a Narrative. So there's a narrative in human society, you know, which, which is encapsulated in the murder of Socrates or the murder of Christ, which is that. That human quality is found in, in exactly that, in. Not in the quantity. It's found in the, in these exceptional shining bright lights that we look to and we align ourselves on. But that most of the stuff is all this really chaotic, dark stuff. So, so the idea that you would extrapolate, you know, mathematically, you know, or statistically from human behavior is insane. That's a crazy thing."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2800.67,"end":2829.12,"speaker":"Dr. Paula Boddington","text":"Yeah. Because I mean, like a really, really strong motivator for human beings is envy, isn't it? So that if you want to be like, if you want to be like, if you want to be picked, if you want to be like, picked for something, there's two ways of doing it. One is to make yourself better than the others, and the other is just to knock the others down because then you're the one who's picked. So envy is such an unbelievably strong motivator. So that if, if it picked on that, where would we be? Where would we be? Would just be just knocked down. Just knocked down all the time."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2829.12,"end":2852,"speaker":"Jonathan Pageau","text":"Yeah. And especially. And what's interesting about the ChatGPTs and the AIs, the way they're being trained now is that they're trained on attention grabbing mechanisms, they're trained on the Internet, they're trained on all these things. The social media platforms, these are really the worst place because they're only there to get your immediate attention."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2852.31,"end":2852.51,"speaker":"Dr. Paula Boddington","text":"Yes."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2852.51,"end":2868.79,"speaker":"Jonathan Pageau","text":"You tend to immediately default to the most immediate, you know, pleasures that we can find, you know, which are, you know, envy. All these things. That's what people are, you know, rage, anger, lust, all these passions are the ones driving these platforms."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2869.03,"end":2939.22,"speaker":"Dr. Paula Boddington","text":"Yes, yes. So. So I mean, one of the things you could say about, about AI acting as a kind of super agency is you can kind of turn it on its head and sort of think what are broad common characteristics of agents? And in terms of a common characteristic, human agents is to actually try to manipulate and dehumanize other people. So manipulate people by dehumanizing. So that's what the age. Ideally, that's what agent. We should treat each other, you know, as Immanuel Kant said and others have said, you know, we should always strive to treat other people as an end in themselves and never merely as a means. But something like the Stuart Russell setup is actually built into it that the AI has been asked to treat the human as a means, as A means to finding out what the humans want. So it's looking at us from, like, from a third person perspective, like a behaviorist would looking at our behavior from the outside. So that's one of the things that's happening in the agency, is that we're seeing it as an agent, partly because some people think it must be an independent agent of its own, but also because we're active, we're allowing it to dehumanize us by focusing our attention on something to avoid something else."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2939.3,"end":2939.78,"speaker":"Jonathan Pageau","text":"Yeah."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2939.94,"end":2993.31,"speaker":"Dr. Paula Boddington","text":"But also the wider metrics that are using, the wider fact is measuring stuff, it means there's some things it's not measuring, so that's left out. So we're just focused on what's measuring. The thing that actually, the one thing that I'm afraid one day I'm going to be like, arrested for shouting at somebody in the street. The thing that really, really upsets me is parents of small children who are just looking at their phones and not talking to their children. It's like, it's actually not funny because human babies, I sort of got. Actually going to get really upset. Human babies and little kids are designed. They're designed to grab our attention. They need it to survive because they don't know how to keep themselves safe. But they also need it for language development, cognitive development. They need constant interaction. Not constant, but, you know. Yeah. I don't know where. It's like, you see, there's so many parents who are just looking at their phones and not looking at their kids. Yeah."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":2993.31,"end":3003.31,"speaker":"Jonathan Pageau","text":"Well, you see that in parks. And I remember even before I had a phone, really late, before I had a phone, I would go play with my kids in the park and I would watch parents sitting on the bench with their phones."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3003.63,"end":3087.79,"speaker":"Dr. Paula Boddington","text":"Yes. Yeah. But another thing it does, it isolates us from each other in ridiculous. In ridiculous way. So here's. Can I give you just a one really stupid. If you look at these tiny little examples, tiny little examples, you can sort of think about, oh, yeah, that's happening in my life and just not do it. So I went from being in a pub with some friends last week and we went to pay. Proudly announced that they don't. It's not just that they only take cards, they pay by QR code. So for one thing, if you hadn't got a smartphone, you couldn't pay. So. But that also meant that the one person who was paying had to scam. Is it proudly saying, oh, it's really good for the environment because we don't have a paper Bill, instead of having a little scrappy, tiny bit of paper bill, they came out, carried out a card, a nice little posh card with the pub's name on, printed on both sides in color. So like, so he's blatantly lying. It's just how it's. It's like a conjuring trick, lying to your face that they're saving paper because he's come out with a piece of paper. And then the person who was paying had to scan it onto his phone so nobody else can see the bill and he's had trouble doing it. So the lie was, this is quicker, it took longer because he had trouble how to do it. And then we paid and then remembered that one of the things we'd ordered hadn't been available. So we wanted to try and check. Did we get charged for cauliflower cheese that we didn't have? Couldn't check because it's vanished. And then the waiter was just like, boasting, boasting, boasting about it. Do I say, listen, mate, read my book? You know, it's just. Honestly."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3087.87,"end":3119.45,"speaker":"Jonathan Pageau","text":"But that's when you wonder what the hell is driving this? Because it's the same, even just the menus. You go into a restaurant and then instead of just giving you a plastic menu, they give you a QR code. You have to scan the QR code and then you're like on your phone trying to figure out the menu. It's so ridiculous. And it's like. But it's so much more complicated. Like, why I don't understand. Like, I do understand. But, you know, it's interesting to notice that it doesn't necessarily make things easier. It's just some fetishization of the process."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3120.25,"end":3187.58,"speaker":"Dr. Paula Boddington","text":"As fetishization of a notion of progress. So it must be progress because you're using technology. It's also excluding people. I mean, like, this is my fault phone. Proudly. This is my phone. I couldn't have paid, I'd have done a washing up. So, but, but it's so excluding people because then. So my friends always ridicule me for that phone. But so that people get picked on and ridiculed. But it's also excluding people because if you had the whole menu, you. I mean, usually they bring menu for more than one people. But if we'd had a paper bill, we could all have looked and said, oh, look, they charge us for qualifier choosing. But we can't, we can't. It's just one, one person looking at it. It, it puts you into that little kind of like it. All these times, it's set souls to us as saving time now. Yes. Sometimes saving a tiny bit of time is. Is what you want. Like if you're at a pit stop in a Grand Prix or if you're trying to save somebody's life in ICU at incremental difference. An incremental difference. You know, that can mean you gradually save more people's lives. But when did anybody go to a restaurant and think the real problem is that it takes 30 seconds to pay the bill? I want to pay it in 25 seconds."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3187.74,"end":3188.22,"speaker":"Jonathan Pageau","text":"Yeah."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3188.54,"end":3189.34,"speaker":"Dr. Paula Boddington","text":"Do you think that."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3189.58,"end":3214.51,"speaker":"Jonathan Pageau","text":"Yeah, yeah, yeah, yeah. So. But. Yeah. So. So what do you think? I mean, what do you think are some of the ways. Because it seems like, I mean, AI is taking over. There's no doubt about it. Like, there's no way around it, really. And so what are the ways, do you think that we can engage with it or not engage with it, you know, that find ways to kind of stay as human as possible in this context?"}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3214.99,"end":3224.99,"speaker":"Dr. Paula Boddington","text":"Well, I kind of think I'd probably say the similar things. Things, similar things to you, really, but we just, we need to do as much as stuff, much stuff as possible in, in the, in the real world."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3225.07,"end":3225.55,"speaker":"Jonathan Pageau","text":"Yeah."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3225.63,"end":3298.61,"speaker":"Dr. Paula Boddington","text":"And, but, but also take the, Take the time and a chance to sort of think really seriously about what it is to be a human being, but, you know, to join in, you know, to join in community, to join in rituals, to sort of see, to, you know, to see people as much as possible, to spend as much time, spend as much time as you can in nature, because wherever you are, you can find a bit of nature. But also just really, just really think. I mean, one of the things you can do is just stop, just kind of stop ribbing your friends for not. That's one of the things that's happening. People get people join in. Or, for example, you can just point, you know, maybe write to institutions and point things out. So. But I noticed, for example, the QR code menace, the National Gallery in London most of all, most all the other places you can get a paper map, you might have to pay a pound for it. So you can get a paper map of the museum and then with your friends, you can say, which gallery do you want to go to? You can have a little look and carry it around with you. The National Gallery, you have to have a QR code on your smartphone. So you could. Maybe I should do that at the end of this, right, to the National Gallery and say, look, you shouldn't do this, for one thing. It's got disability implications because not everybody can read stuff on the smartphone. You know, it's too. So small."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3299.49,"end":3305.25,"speaker":"Jonathan Pageau","text":"It's a ridiculous thing. It's like it's so unpractical to look at them, to look at the map on your smartphone."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3305.65,"end":3362.18,"speaker":"Dr. Paula Boddington","text":"Yeah. So, but I would. I would just. I would just suggest just look at how it's just become integrated into the infrastructure of everything you do and just, Just ask yourself, is that what you. I mean, maps, for example. It's really undermining people's capacity to. I was. I was walking somewhere the other day in London and we. It's a slightly confusing area because the streets just go out at different angles and we had to try to get to St Pancras. I said, oh, sorry, we're heading north, it's fine. So how do you know we're heading north? Well, because of the shadows on the buildings. It's west over there. It's. You know what I mean? It's that kind of thing. Sorry, it's just, it just, just look. That's why I think it's, like, important to think about what the agency is doing in really kind of minute little details, because that's the only. Only place. That's the only place we have to try to try to think about. Unless you happen to be, you know, have. Have some particular position."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3364.42,"end":3376.55,"speaker":"Jonathan Pageau","text":"Yeah. All right. All right. Let's take that as a lesson for today. So. So, Paula, where can people get your book if they are interested in your. In your textbook? Is it possible to get it somewhere online or to order it?"}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3376.79,"end":3391.51,"speaker":"Dr. Paula Boddington","text":"Oh, you can get. I mean, you can get it. You can get it from the Springer website. It's on. You can get it on Amazon. You can get it on all the usual. On all the usual places. It's quite expensive because it's long. It's a textbook. Or get. Or get your school or university library to."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3391.64,"end":3392.2,"speaker":"Jonathan Pageau","text":"To get it."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3392.44,"end":3446.77,"speaker":"Dr. Paula Boddington","text":"Yeah. So, yeah. So one of the things. One of the things I've tried to do is called AI Ethics. But one of the things I do is actually explain how the standard ways of looking at ethics just don't work. They break down when we're looking at AI and how you need to look at notions of human nature. I mean, there's stuff in there about religion, actually, because I talk about how many of the visions of AI are actually fundamentally really, really religious. And we need to understand. Understand the roots of that in order to understand. In order to understand what visions of the future are being presented to us, what position of Humans, how it's understanding a position of humans. I mean, some of the stuff is. Some of the stuff bears uncanny resemblance to lots of religious ideas. Like the general idea that humans are really special because we're the ones in a position who are going to be able to create this fantastic being who's going to be fulfillment of universe."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3447.01,"end":3514.34,"speaker":"Jonathan Pageau","text":"Well, one of the things that it seems that we could use right now is an understanding of non human agency and what those non human agencies were understood to be like in the ancient world. And this is going to sound silly to people, but yeah, fairies and all these little types of agencies. How is it that ancient people understood them? Like the demons, the angels, you know, how do they see them acting on people and how do they see their agency kind of manifesting itself? I think that we've evacuated all these ideas of non human agency and now we're basically dealing with the problem of non human agency. But we don't have any of the tools to deal with them because we don't understand them. We don't think about, you know, the idea of. If you think about, for example, a fairy tale like the Shoemaker and the Elves and the notion of, of action that is beyond the will of the, of the, of the person. It's like these, these tropes that are in fairy tales, you know, the Pucks and all these kind of household agencies. These are important in understanding the way and the dangers of non human agency in our lives."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3514.5,"end":3539.83,"speaker":"Dr. Paula Boddington","text":"Yeah, yeah. I mean that's, that's, that's one of the dangers of the way in which we've been encouraged to think about the mind in a purely sort of Cartesian mental way. Because we have this illusion then that we have. We are totally in control of our minds and that we're just undermined by the constant need for affirmation from other people. But we're just isolated from other people. I mean, are you familiar with Canadian philosopher Charles Taylor?"}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3539.83,"end":3540.35,"speaker":"Jonathan Pageau","text":"Yep."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3540.59,"end":3560.63,"speaker":"Dr. Paula Boddington","text":"Yeah. Like his distinction between the buffered self and poorer self. Poor self. Yeah, yeah. Those kinds of ideas are ones that people well worth, well worth thinking about in terms of. We just got this idea, but we're just completely buffered, which means actually we're not. We're more poorest than ever."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3561.27,"end":3582.98,"speaker":"Jonathan Pageau","text":"Exactly. And then as people. Yeah, and as people kind of join with their AI familiar, they'll have this little AI familiar that'll be working for them. You know, it's like you should start to think about these old stories again because, yeah, the buffered self is over. We are moving into a very, very ambiguous state of relationship of identities and agencies."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3583.86,"end":3586.34,"speaker":"Dr. Paula Boddington","text":"Are you going to do the Elves and the Shoemaker in one of your stories?"}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3586.9,"end":3643.96,"speaker":"Jonathan Pageau","text":"Yeah, we'll see. It's not part of the plan for now, but that could be an interesting idea. You know, I'm trying to think about it in terms of. Obviously, I'm just telling the story. It really is just a fairy tale. But I do want there to be a certain angle in it that is alluding to some of the things that are going on now. Like in Snow White, we did a whole, you know, host. There's a whole aspect of Snow White which is the obsession that the queen has with the mirror and the mirror revealing who's most beautiful in it. And so this. This whole idea of vanity and of the cell phone and of the, you know, this affirming machine that's affirming or denying your value. Value. You know, it's like, it's so relevant today that, you know, there's a. That's a. There's more emphasis on that in the way that I tell the story. And so I think it's the same with something like Shoemaker and the Elves. I would have to find a way to explain these kind of agencies that are acting out on the side of our will and how they're. And how to deal with them in a way that would be helpful for people. So. Yeah, it's a good idea. Think about it."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3644.44,"end":3645.88,"speaker":"Dr. Paula Boddington","text":"Great. It's my favorite one, actually."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3646.12,"end":3661.98,"speaker":"Jonathan Pageau","text":"Yeah, I love that story. Definitely. Definitely. All right, everyone, so if you can. You can check out Paula's book. And thanks again for your time and your thought about all these crazy. These crazy times. I really appreciate it."}
{"episode_id":"SW - #299 - 2023-08-03 - Dr. Paula Boddington - A.I. Ethics","start":3661.98,"end":3663.5,"speaker":"Dr. Paula Boddington","text":"Thanks. Great to talk to you."}
